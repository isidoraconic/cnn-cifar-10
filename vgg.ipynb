{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXIUZXJlveOZ"
      },
      "outputs": [],
      "source": [
        "#Importing necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import sklearn as sklearn\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "from keras.datasets import cifar10\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras.layers import BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTwdpzS8vrGB"
      },
      "outputs": [],
      "source": [
        "(X_train_full, y_train_full), (X_test_full, y_test_full) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqY0tL5yvv94"
      },
      "outputs": [],
      "source": [
        "#Prep-processing to change the shape of input\n",
        "\n",
        "#Tranforming categorical data to encoded (numerical) values\n",
        "y_train_full = to_categorical(y_train_full, num_classes=10)\n",
        "y_test_full = to_categorical(y_test_full, num_classes=10)\n",
        "\n",
        "#Transform images from (32,32,3) to 3072-dimensional vectors (32*32*3)\n",
        "# X_train_full = np.reshape(X_train_full,(50000,3072))\n",
        "# X_test_full = np.reshape(X_test_full,(10000,3072))\n",
        "X_train_full = X_train_full.astype('float32')\n",
        "X_test_full = X_test_full.astype('float32')\n",
        "\n",
        "#Normalizing the pixel values to 0-1\n",
        "X_train_full /= 255\n",
        "X_test_full /= 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xd3xL-gQvyfd"
      },
      "outputs": [],
      "source": [
        "#Now we have to split the train data into train and test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train_full, y_train_full, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcBza9FOwS4C"
      },
      "outputs": [],
      "source": [
        "#Data augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.RandomFlip('horizontal'),\n",
        "  layers.RandomFlip('vertical'),\n",
        "  layers.RandomRotation(0.2)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUSrdDhlv0w6"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential()\n",
        "weight_decay = 0.0005\n",
        "x_shape = [32,32,3]\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), padding='same', input_shape=x_shape, kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.3))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.4))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.4))\n",
        "\n",
        "model.add(layers.Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.4))\n",
        "\n",
        "model.add(layers.Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.4))\n",
        "\n",
        "model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.4))\n",
        "\n",
        "model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.4))\n",
        "\n",
        "model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(layers.Dropout(0.4))\n",
        "\n",
        "model.add(layers.Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(layers.Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(10))\n",
        "model.add(layers.Activation('softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NC_a6xakwtNK"
      },
      "outputs": [],
      "source": [
        "adam = Adam(learning_rate=0.001,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=False)\n",
        "sgd = keras.optimizers.SGD(learning_rate=0.2, momentum=0.9, decay=0.01)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=adam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OU8WHlsSwwAw",
        "outputId": "62a9ea9f-99d4-4000-8d32-d27ed747a5c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "875/875 - 63s - loss: 4.5119 - accuracy: 0.2365 - val_loss: 4.3118 - val_accuracy: 0.2341 - 63s/epoch - 72ms/step\n",
            "Epoch 2/15\n",
            "875/875 - 20s - loss: 3.2683 - accuracy: 0.3972 - val_loss: 2.9323 - val_accuracy: 0.4039 - 20s/epoch - 23ms/step\n",
            "Epoch 3/15\n",
            "875/875 - 20s - loss: 2.5528 - accuracy: 0.4892 - val_loss: 2.4348 - val_accuracy: 0.4951 - 20s/epoch - 23ms/step\n",
            "Epoch 4/15\n",
            "875/875 - 20s - loss: 2.1843 - accuracy: 0.5497 - val_loss: 2.3622 - val_accuracy: 0.5064 - 20s/epoch - 23ms/step\n",
            "Epoch 5/15\n",
            "875/875 - 20s - loss: 2.0578 - accuracy: 0.5807 - val_loss: 1.9110 - val_accuracy: 0.6194 - 20s/epoch - 23ms/step\n",
            "Epoch 6/15\n",
            "875/875 - 20s - loss: 2.0402 - accuracy: 0.5933 - val_loss: 1.8917 - val_accuracy: 0.6373 - 20s/epoch - 23ms/step\n",
            "Epoch 7/15\n",
            "875/875 - 20s - loss: 2.0757 - accuracy: 0.6030 - val_loss: 2.0545 - val_accuracy: 0.5976 - 20s/epoch - 23ms/step\n",
            "Epoch 8/15\n",
            "875/875 - 20s - loss: 2.1218 - accuracy: 0.6114 - val_loss: 2.1012 - val_accuracy: 0.6146 - 20s/epoch - 23ms/step\n",
            "Epoch 9/15\n",
            "875/875 - 20s - loss: 2.1665 - accuracy: 0.6199 - val_loss: 2.3025 - val_accuracy: 0.5746 - 20s/epoch - 23ms/step\n",
            "Epoch 10/15\n",
            "875/875 - 20s - loss: 2.1464 - accuracy: 0.6288 - val_loss: 2.2402 - val_accuracy: 0.6020 - 20s/epoch - 23ms/step\n",
            "Epoch 11/15\n",
            "875/875 - 20s - loss: 2.1750 - accuracy: 0.6332 - val_loss: 2.3900 - val_accuracy: 0.5904 - 20s/epoch - 23ms/step\n",
            "Epoch 12/15\n",
            "875/875 - 20s - loss: 2.1343 - accuracy: 0.6476 - val_loss: 2.8054 - val_accuracy: 0.4304 - 20s/epoch - 23ms/step\n",
            "Epoch 13/15\n",
            "875/875 - 20s - loss: 2.1017 - accuracy: 0.6544 - val_loss: 1.9984 - val_accuracy: 0.6837 - 20s/epoch - 23ms/step\n",
            "Epoch 14/15\n",
            "875/875 - 20s - loss: 2.0694 - accuracy: 0.6648 - val_loss: 2.0298 - val_accuracy: 0.6813 - 20s/epoch - 23ms/step\n",
            "Epoch 15/15\n",
            "875/875 - 20s - loss: 2.0243 - accuracy: 0.6708 - val_loss: 1.9582 - val_accuracy: 0.6723 - 20s/epoch - 23ms/step\n"
          ]
        }
      ],
      "source": [
        "#Training the CNN\n",
        "history = model.fit(X_train, y_train, batch_size=32, epochs=15, verbose=2, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5enKEvEwzs3"
      },
      "outputs": [],
      "source": [
        "score = model.evaluate(X_test, y_test, batch_size=128, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-dlnz3Ww2Ub",
        "outputId": "db8b9b51-4abd-45ac-9508-9af73f80e599"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['loss', 'accuracy']\n",
            "[1.9447767734527588, 0.6727333068847656]\n"
          ]
        }
      ],
      "source": [
        "print(model.metrics_names)\n",
        "print(score)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "vgg.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}